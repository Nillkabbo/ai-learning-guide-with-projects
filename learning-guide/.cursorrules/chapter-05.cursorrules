# Chapter 5: A Developer's Guide to the OpenAI API - Cursor Rules

## Chapter Context

This chapter provides complete, hands-on guide to OpenAI API. Students learn system messages, conversation history, parameters, streaming, function calling, and multimodal capabilities. This is foundational for all future API work.

## Key Concepts

### 1. System Messages
- Define AI personality and behavior
- First message in conversation
- High-level directive
- Works identically in OpenAI and Ollama
- Primary tool for specialization

### 2. Conversation History
- AI is stateless—you provide memory
- Send full history with each request
- Message list: system, user, assistant
- Chatbot class pattern for management
- Context retention through history

### 3. Temperature and Max Tokens
- Temperature: randomness control (0.0 = deterministic, 1.0+ = creative)
- Max tokens: response length limit
- Balance creativity vs. coherence
- Cost control mechanism
- Task-specific parameter selection

### 4. Streaming
- Real-time token-by-token output
- Better user experience
- Streaming vs. non-streaming
- Both OpenAI and Ollama support
- Progress indication

### 5. Function Calling
- Two-step process: AI decides → you execute
- Connect AI to external systems
- Tool descriptions (JSON schema)
- Function execution and result feedback
- Powerful pattern for real-world apps

### 6. Multimodal Capabilities
- Vision: image analysis (gpt-4o, llava)
- Audio: speech-to-text (Whisper), text-to-speech (TTS)
- Base64 encoding for images
- Model requirements vary
- OpenAI: native support, Ollama: model-dependent

## Important Code Patterns

### Basic API Call
```python
import openai
client = openai.OpenAI()
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello!"}]
)
print(response.choices[0].message.content)
```

### System Message
```python
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is AI?"}
]
```

### Conversation History
```python
class Chatbot:
    def __init__(self):
        self.history = [{"role": "system", "content": "..."}]
    
    def chat(self, message: str):
        self.history.append({"role": "user", "content": message})
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=self.history
        )
        ai_msg = response.choices[0].message.content
        self.history.append({"role": "assistant", "content": ai_msg})
        return ai_msg
```

### Temperature Control
```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    temperature=0.7,  # Balanced
    max_tokens=500    # Length limit
)
```

### Streaming
```python
stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    stream=True
)
for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### Function Calling
```python
# Step 1: Define tools
tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get weather for location",
        "parameters": {...}
    }
}]

# Step 2: AI decides to call
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    tools=tools
)

# Step 3: Execute function and send result back
if response.choices[0].message.tool_calls:
    # Execute function
    # Send result back to AI
```

## Common Mistakes to Avoid

1. **Forgetting System Messages**: Always define AI personality
2. **Not Managing History**: AI has no memory without history
3. **Wrong Temperature**: Use 0.0-0.3 for facts, 0.7 for balanced, 1.0+ for creative
4. **Ignoring Max Tokens**: Can lead to unexpected costs
5. **Not Using Streaming**: Always improves UX for longer responses
6. **Unsafe Function Execution**: Always validate inputs
7. **Not Handling Errors**: API calls can fail

## Integration Points

### Prerequisites (Chapters 1-4)
- Basic AI concepts
- Message structure
- Development environment
- API key security

### Next Chapter Preparation (Chapter 6)
- API patterns transfer to Claude
- Function calling concepts apply
- Streaming works similarly
- Multimodal concepts extend

## Project Context

### Chapter 5 Project: E-Commerce Recommendation Assistant
- **Type**: Cumulative (builds on Chapters 1-4)
- **Focus**: All API features in one app
- **Key Skills**: System messages, history, function calling, streaming
- **Extension Opportunities**: Vision, audio, web interface

## Code Style and Best Practices

### System Messages
- Be specific and clear
- Define role and personality
- Set behavior guidelines
- Test different personas

### Conversation History
- Always include system message
- Maintain full history
- Consider context limits
- Implement reset functionality

### Function Calling
- Describe functions clearly
- Validate all inputs
- Handle errors gracefully
- Test function execution

### Streaming
- Always use for longer responses
- Provide progress indication
- Handle streaming errors
- Improve user experience

## Learning Progression

### What Students Should Master
1. ✅ Can make API calls confidently
2. ✅ Understands system messages
3. ✅ Can manage conversation history
4. ✅ Knows when to use temperature values
5. ✅ Can implement streaming
6. ✅ Understands function calling flow
7. ✅ Can work with images/audio

## Related Chapters

- **Chapter 1-4**: Foundation concepts
- **Chapter 6**: Claude API (similar patterns)
- **Chapter 8**: API design patterns (extends concepts)
- **Chapter 14**: Function calling (deep dive)
- **Chapter 17**: Web applications (uses all concepts)

## Memory Context for Next Session

When continuing to Chapter 6, remember:
- Students understand OpenAI API patterns
- They know system messages, history, streaming
- They understand function calling
- They can build complete applications
- These patterns transfer to other APIs
